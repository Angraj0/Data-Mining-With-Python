{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 9.Association_Rules.ipynb","private_outputs":true,"provenance":[{"file_id":"1sk8WRLXRRzE4SaSCQbQw06NgwGxelLZg","timestamp":1643378933498}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SQzsqmD7bLvL"},"source":["# **Installing packages and importing libraries**"]},{"cell_type":"code","metadata":{"id":"DGF1FmnuUv1a"},"source":["!pip install squarify"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpBGKLVWQBwV"},"source":["# for basic operations\n","import numpy as np\n","import pandas as pd\n","\n","# for visualizations\n","import matplotlib.pyplot as plt\n","import squarify\n","import seaborn as sns\n","plt.style.use('fivethirtyeight')\n","\n","# for defining path\n","import os\n","\n","# for market basket analysis\n","from mlxtend.frequent_patterns import apriori\n","from mlxtend.frequent_patterns import association_rules"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCtu167FQEU4"},"source":["# **Dataset for Lab 9**\n","\n","**Data Set Information:**\n","\n","We have a dataset of a mall with 7500 transactions of different customers buying different items from the store. We have to find correlations between the different items in the store. so that we can know if a customer is buying apple, banana and mango. what is the next item, The customer would be interested in buying from the store.\n","\n","\n","**Problem Statement**\n","\n","Market owners should want to know what customers will buy next by looking at the products they buy, so that market owners can adjust their product placement to increase product sales. This can be overcome by using the Apriori Algorithm to perform a Market Basket Analysis of the customer's buying behavior. \n","\n","The dataset can be found here in this [URL](https://drive.google.com/file/d/1DDtVOZwFQJBn0zXc69sfb2zld1PofX57/view?usp=sharing)"]},{"cell_type":"code","metadata":{"id":"t4yZD0OacRNd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Fh8U31FLDD0"},"source":["## **Loading the dataset**"]},{"cell_type":"code","metadata":{"id":"6ifg8k1DIXMK"},"source":["import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/Angraj project dmkd/01. bank-additional-full.csv',header=None, sep=\";\")\n","\n","#Check number of rows and columns in the dataset\n","print(\"The dataset has %d rows and %d columns.\" % df.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ooT-6JBfVCBL"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"BWeIYyFwrr2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre_df = df.copy()\n","pre_df.drop([4,7,8,9,10,12],axis=1,inplace=True)\n","pre_df.head(10)"],"metadata":{"id":"PCAIWZzRrzof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","pre_df.drop([0],axis=0,inplace=True)\n","pre_df.head(10)"],"metadata":{"id":"tW7HwacxDpKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"The dataset has %d rows and %d columns.\" % pre_df.shape)"],"metadata":{"id":"yl8neyt2xPLX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPzP4RsHGXbC"},"source":["# **Dataset Visualization**\n"]},{"cell_type":"markdown","metadata":{"id":"ZFeoqhw8G4vn"},"source":["The bigger words in the wordcloud depicts the most used job sector in the data set"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from wordcloud import WordCloud\n","\n","plt.rcParams['figure.figsize'] = (15, 15)\n","wordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(str(pre_df[1]))\n","plt.imshow(wordcloud)\n","plt.axis('off')\n","plt.title('Most Popular word',fontsize = 20)\n","plt.show()\n"],"metadata":{"id":"AiFV-TJdB80E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = df[1].value_counts().head(40000).to_frame()\n","y.index"],"metadata":{"id":"9KEToA9aEW_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plotting a tree map\n","\n","plt.rcParams['figure.figsize'] = (20, 20)\n","color = plt.cm.cool(np.linspace(0, 1, 40))\n","squarify.plot(sizes = y.values, label = y.index, alpha=.8, color = color)\n","plt.title('Tree Map for Popular Items')\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"DYuvUzfrElPV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSCHSX0HGBCf"},"source":["# **Data Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"v-xsdEkLNpO5"},"source":["There are two principal methods of representing this type of market basket data:\n","using either the transactional data format or the tabular data format. The transactional data format requires only two fields, an ID field and a content field,\n","with each record representing a single item only.\n","\n","For example, the data in Table 1 could be represented using transactional data\n","format as shown in Table 2. In the tabular data format, each record represents\n","a separate transaction, with as many 0/1 flag fields as there are items. The data\n","from Table 2 could be represented using the tabular data format, as shown in\n","Figure 1."]},{"cell_type":"code","metadata":{"id":"QNtky4HNVlBD"},"source":["# making each customers shopping items an identical list\n","trans = []\n","for i in range(0, 41188):\n","    trans.append([str(pre_df.values[i,j]) for j in range(0, 15)])\n","\n","# conveting it into an numpy array\n","trans = np.array(trans)\n","\n","# checking the shape of the array\n","print(trans.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpvAA_Rw5Jwx"},"source":["trans[:,0:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xg5DZC7UVnKz"},"source":["import pandas as pd\n","from mlxtend.preprocessing import TransactionEncoder\n","\n","te = TransactionEncoder()\n","pre_df = te.fit_transform(trans)\n","pre_df= pd.DataFrame(pre_df, columns = te.columns_)\n","\n","# getting the shape of the data\n","pre_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-F0baiZlchv"},"source":["pre_df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJgP0Rq7VrIM"},"source":["pre_df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpZTJS5pVsoR"},"source":["pre_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQ2CJwlAevKC"},"source":["# **Apriori Algorithm**"]},{"cell_type":"markdown","metadata":{"id":"_4_M8dhEe7WT"},"source":["The algorithm was first proposed in 1994 by Rakesh Agrawal and Ramakrishnan Srikant. Apriori algorithm finds the most frequent itemsets or elements in a transaction database and identifies association rules between the items just like the above-mentioned example."]},{"cell_type":"markdown","metadata":{"id":"4Nh_p2xEfI3Y"},"source":["To construct association rules between elements or items, the algorithm considers 3 important factors which are, support, confidence and lift. Each of these factors is explained as follows:\n","\n","**Support**:\n","\n","The support of item I is defined as the ratio between the number of transactions containing the item I by the total number of transactions expressed as the equation specified in the Lecture slides.\n","\n","**Confidence**:\n","\n","This is measured by the proportion of transactions with item I1, in which item I2 also appears. The confidence between two items I1 and I2, in a transaction is defined as the total number of transactions containing both items I1 and I2 divided by the total number of transactions containing I1. ( Assume I1 as X , I2 as Y )\n","\n","**Lift**:\n","\n","Lift is the ratio between the confidence and support."]},{"cell_type":"markdown","metadata":{"id":"dtXOYbuPfdE5"},"source":["**Strong Rules**\n","\n","Analysts may prefer rules that have either high support or high confidence, and\n","usually both. Strong rules are those that meet or surpass certain minimum support and confidence criteria.\n","For example, an analyst interested in finding which supermarket items are purchased together may set a minimum support level of 20% and a minimum confidence level of 70%. On the other hand, a fraud detection analyst or a terrorism\n","detection analyst would need to reduce the minimum support level to 1% or less,\n","since comparatively few transactions are either fraudulent or terror-related."]},{"cell_type":"markdown","metadata":{"id":"kqRxTA3Tf2LJ"},"source":["**Itemset**\n","\n","An itemset is a set of items contained in $I$ , and a $k-itemset$ is an itemset containing\n","$k$ items. For example, \\{beans, squash\\} is a 2-itemset, and \\{broccoli, green peppers,\n","corn\\} is a 3-itemset, each from the vegetable stand set $I$. The itemset frequency is\n","simply the number of transactions that contain the particular itemset.\n","\n","A frequent\n","itemset is an itemset that occurs at least a certain minimum number of times, having\n","itemset frequency $\\geq \\phi$. For example, suppose that we set $\\phi = 4.$ Then itemsets that\n","occur more than four times are said to be frequent. We denote the set of frequent\n","$k$-itemsets as $F_{k}$."]},{"cell_type":"markdown","metadata":{"id":"r36Hz-cKgGCw"},"source":["## **Finding Frequent itemsets**"]},{"cell_type":"code","metadata":{"id":"sXYPoNSPVvYF"},"source":["from mlxtend.frequent_patterns import apriori\n","\n","#Now, let us return the items and itemsets with at least 5% support:\n","apriori(pre_df, min_support = 0.01, use_colnames = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eY5JH5aSVyhI"},"source":["frequent_itemsets = apriori(pre_df, min_support = 0.05, use_colnames=True)\n","frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n","frequent_itemsets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgf7fB5VV0Ni"},"source":["# getting th item sets with length = 2 and support more han 10%\n","\n","frequent_itemsets[ (frequent_itemsets['length'] == 2) &\n","                   (frequent_itemsets['support'] >= 0.01) ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lMp9cVKSgOpU"},"source":["## Finding Association Rules"]},{"cell_type":"code","metadata":{"id":"vqWae1pxWIvj"},"source":["rules_mlxtend = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.02)\n","rules_mlxtend.sort_values(by=[\"support\"],ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yTMkWTxWQgr"},"source":["rules_mlxtend[ (rules_mlxtend['lift'] >= 1) & (rules_mlxtend['confidence'] >= 0.3) ].head()"],"execution_count":null,"outputs":[]}]}